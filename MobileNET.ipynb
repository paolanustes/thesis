{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MobileNET.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paolanustes/thesis/blob/main/MobileNET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzZFubBUNrbd"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Is0lE_BUAQ4G"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQRi5KDnCXrW"
      },
      "source": [
        "!pip install -q rasterio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVsLcgpxAjrE"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import random\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import rasterio\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZnbfI1vPGNK"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Own2NuCOA_a"
      },
      "source": [
        "# Import input dataset images (GeoTIFF)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JjnwqgvG1GM"
      },
      "source": [
        "SEED = 1009\n",
        "name = 'model_x'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DB2DlTtCB4Mn"
      },
      "source": [
        "files_dams = [str(f) for f in pathlib.Path('/content/drive/MyDrive/Dam_CA_tif/').glob('*.tif')]\n",
        "files_nodams = [str(f) for f in pathlib.Path('/content/drive/MyDrive/No_dam_CA_tif/').glob('*.tif')] # TODO: add no dams\n",
        "\n",
        "files = files_dams + files_nodams\n",
        "labels = [1] * len(files_dams) + [0] * len(files_nodams)\n",
        "\n",
        "df = pd.DataFrame({ 'file': files, 'label': labels })\n",
        "df = df.sample(frac=1, random_state=SEED)\n",
        "df.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUwTdblQYONF"
      },
      "source": [
        "BUFFER = len(files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lSh6jadPShA"
      },
      "source": [
        "image = rasterio.open(files[0])\n",
        "band_names = image.descriptions\n",
        "print(band_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmeJC9GlJOsL"
      },
      "source": [
        "## define bands to use \n",
        "\n",
        "UseBands = ['R', 'G', 'B', 'occurrence', 'slope']\n",
        "indexBands = [band_names.index(s) for s in UseBands]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bG-mHSifUNS-"
      },
      "source": [
        "def _bytes_feature(value):\n",
        "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "  if isinstance(value, type(tf.constant(0))):\n",
        "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _float_feature(value):\n",
        "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6be-L3QHBgRx"
      },
      "source": [
        "SIZE = 220\n",
        "\n",
        "def serialize_example(path, label):\n",
        "  image = rasterio.open(path)\n",
        "  \n",
        "  image = image.read()\n",
        "\n",
        "  image = image[:, :SIZE, :SIZE] # crop, sometimes images are of a different size?\n",
        "  image[np.isnan(image)] = 0\n",
        "  image = image.astype(np.float32)\n",
        "\n",
        "  feature = {}\n",
        "\n",
        "  for i, band_name in zip(indexBands, UseBands):\n",
        "\n",
        "    im = image[i]\n",
        "\n",
        "    if band_name in ['R','G','B']: # Normalize \n",
        "      im = im / 255.\n",
        "\n",
        "    feature[band_name] = _bytes_feature(im.tobytes())\n",
        "  \n",
        "  feature['label'] = _int64_feature(label)\n",
        "\n",
        "  return tf.train.Example(features=tf.train.Features(feature=feature)).SerializeToString()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cODp52YOMX4"
      },
      "source": [
        "# Write TFRecord"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCi-huo-PEIh"
      },
      "source": [
        "# Create a dictionary describing the format\n",
        "tfrecord_format = {\n",
        "  'label':  tf.io.FixedLenFeature(shape=[], dtype=tf.int64),\n",
        "}\n",
        "\n",
        "for band_name in UseBands:\n",
        "  tfrecord_format[band_name] = tf.io.FixedLenFeature(shape=[], dtype=tf.string)\n",
        "\n",
        "def _parse_image_function(example):\n",
        "  example = tf.io.parse_example(example, tfrecord_format)\n",
        "\n",
        "  images = []\n",
        "\n",
        "  for band_name in UseBands:\n",
        "    image = tf.io.decode_raw(example[band_name], out_type=float)\n",
        "    image = tf.reshape(image, [SIZE, SIZE])\n",
        "    images.append(image)\n",
        "\n",
        "  image = tf.stack(images, 2)\n",
        "\n",
        "  return image, example['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdgZtE4-n7SZ"
      },
      "source": [
        "!rm *.tfrec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEM3mhJMhlbk"
      },
      "source": [
        "for index, row in df.iloc[10:20].iterrows():\n",
        "  print(row.file, row.label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BS7hGSUiIpG4"
      },
      "source": [
        "count=20\n",
        "total=len(df)\n",
        "\n",
        "for i, start in enumerate(tqdm(range(0, total, count))):\n",
        "  stop = min(start + count, total) # make sure we're not over max number of rows\n",
        "  count = stop - start # number of examples to write\n",
        "  filename = f'file_dams-{i:02d}-{count:02d}.tfrec'\n",
        "  \n",
        "  with tf.io.TFRecordWriter(filename) as writer:\n",
        "    for index, row in df.iloc[start:stop].iterrows():\n",
        "      example = serialize_example(row.file, row.label)\n",
        "      writer.write(example)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oOJs4QXx-Q4"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HtSkIQqOY0s"
      },
      "source": [
        "# Split and visualize training, validation, and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVhPansUHq36"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "ds = tf.data.TFRecordDataset([str(f) for f in pathlib.Path('./').glob('*.tfrec')])\n",
        "ds = ds.map(_parse_image_function)\n",
        "\n",
        "ds = ds.shuffle(buffer_size=BUFFER, seed=SEED)\n",
        "ds = ds.batch(BATCH_SIZE)\n",
        "ds = ds.prefetch(tf.data.AUTOTUNE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNGwLc8VH63Y"
      },
      "source": [
        "# example = next(ds.as_numpy_iterator())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QUenrfznQla"
      },
      "source": [
        "# example[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMPJi4Sbrply"
      },
      "source": [
        "# N = 3\n",
        "# iter = ds.as_numpy_iterator()\n",
        "# fig, ax = plt.subplots(N, 3, figsize=(12, 3*N))\n",
        "\n",
        "# for i in range(N):\n",
        "#   example = next(iter)\n",
        "#   image = example[0][0] #np.transpose(example[0][0], (1, 2, 0))\n",
        "#   print(f'Label: {example[1][0]}')\n",
        "#   ax[i,0].imshow(image[:, :, :3])\n",
        "#   ax[i,0].set_title('RGB')\n",
        "#   ax[i,1].imshow(image[:, :, 4], cmap='Greys')\n",
        "#   ax[i,1].set_title('ndwi')\n",
        "#   ax[i,2].imshow(image[:, :, 4])\n",
        "#   ax[i,2].set_title('elevation');\n",
        "\n",
        "# plt.tight_layout()\n",
        "# # fig, ax = plt.subplots(1, 7, figsize=(25, 3))\n",
        "# # image = np.transpose(example[0][0], (1, 2, 0))\n",
        "# # print(f'Label: {example[1][0]}')\n",
        "# # ax[0].imshow(image[:, :, :3] / 255.0)\n",
        "# # ax[0].set_title('RGB')\n",
        "# # ax[1].imshow(image[:, :, [3, 3, 1]] / 255.0)\n",
        "# # ax[1].set_title('NNG')\n",
        "# # ax[2].imshow(image[:, :, 5], cmap='Greys')\n",
        "# # ax[2].set_title('NDWI')\n",
        "# # ax[3].imshow(image[:, :, 4])\n",
        "# # ax[3].set_title('occurrence')\n",
        "# # ax[4].imshow(image[:, :, 6])\n",
        "# # ax[4].set_title('aspect')\n",
        "# # ax[5].imshow(image[:, :, 7]) \n",
        "# # ax[5].set_title('slope')\n",
        "# # ax[6].imshow(image[:, :, 8])\n",
        "# # ax[6].set_title('elevation');\n",
        "\n",
        "# plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSApwfQeD45j"
      },
      "source": [
        "# Count the records\n",
        "records_n = sum(1 for record in ds)\n",
        "print(\"records_n = {}\".format(records_n))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QoeQF0qeTn5"
      },
      "source": [
        "train_size = int(0.7 * records_n)\n",
        "val_size = int(0.20 * records_n)\n",
        "test_size = int(0.10 * records_n)\n",
        "\n",
        "train_dataset = ds.take(train_size)\n",
        "test_dataset = ds.skip(train_size)\n",
        "val_dataset = test_dataset.take(val_size)\n",
        "test_dataset = test_dataset.skip(val_size)\n",
        "\n",
        "train_dataset = train_dataset.shuffle(buffer_size=train_size, seed=SEED)\n",
        "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "val_dataset = val_dataset.shuffle(buffer_size=val_size, seed=SEED)\n",
        "val_dataset = val_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "test_dataset = test_dataset.shuffle(buffer_size=test_size, seed=SEED)\n",
        "test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzO0R8lCLOqF"
      },
      "source": [
        "# for image, label in train_dataset:\n",
        "#   image, label = next(train_dataset.as_numpy_iterator())\n",
        "\n",
        "#   plt.figure(figsize=(20, 10))\n",
        "#   for i in range(32):\n",
        "#     ax=plt.subplot(4, 8, i+1)\n",
        "#     plt.imshow(image[i])\n",
        "#     plt.title(label[i])\n",
        "#     plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVFWuySOLOiD"
      },
      "source": [
        "# for image, label in test_dataset:\n",
        "#   image, label = next(test_dataset.as_numpy_iterator())\n",
        "\n",
        "#   plt.figure(figsize=(20, 10))\n",
        "#   for i in range(32):\n",
        "#     ax=plt.subplot(4, 8, i+1)\n",
        "#     plt.imshow(image[i])\n",
        "#     plt.title(label[i])\n",
        "#     plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7Xh-LA2EN5k"
      },
      "source": [
        "# for image, label in val_dataset:\n",
        "#   image, label = next(val_dataset.as_numpy_iterator())\n",
        "\n",
        "#   plt.figure(figsize=(20, 10))\n",
        "#   for i in range(32):\n",
        "#     ax=plt.subplot(4, 8, i+1)\n",
        "#     plt.imshow(image[i])\n",
        "#     plt.title(label[i])\n",
        "#     plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9Y9bu-COmvT"
      },
      "source": [
        "# Model set-up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4O6sVru6TQP"
      },
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "CHANNELS = len(UseBands)\n",
        "IMG_SIZE = (220, 220, CHANNELS)\n",
        "NUM_CLASSES = 2\n",
        "\n",
        "def get_model(IMG_SIZE, NUM_CLASSES):\n",
        "  dense_input = tf.keras.layers.Input(shape=IMG_SIZE)\n",
        "  dense_filter = tf.keras.layers.Conv2D(3, CHANNELS, padding='same')(dense_input)\n",
        "\n",
        "  # Create the base model from the pre-trained model MobileNet V2\n",
        "  base_model = tf.keras.applications.MobileNetV2(include_top=False,\n",
        "                                                weights='imagenet')\n",
        "\n",
        "  base_model.trainable = False\n",
        "\n",
        "  global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "\n",
        "  prediction_layer = tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "  inputs = dense_input\n",
        "  x = base_model(dense_filter)\n",
        "  x = global_average_layer(x)\n",
        "  x = tf.keras.layers.Dropout(0.2)(x)\n",
        "  outputs = prediction_layer(x)\n",
        "  model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "  return model\n",
        "\n",
        "base_learning_rate = 0.001\n",
        " \n",
        "# Free up RAM in case the model definition cells were run multiple times\n",
        "keras.backend.clear_session()\n",
        "\n",
        "# # Build model\n",
        "\n",
        "model = get_model(IMG_SIZE, NUM_CLASSES)\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True, label_smoothing=0.01),\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9Q9j7Re7IUg"
      },
      "source": [
        "\n",
        "checkpoint_path = f\"/content/drive/MyDrive/Thesis/SA/{name}/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = [\n",
        "              #  tf.keras.callbacks.EarlyStopping(patience=5),\n",
        "               tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1),\n",
        "               tf.keras.callbacks.CSVLogger(f\"/content/drive/MyDrive/Thesis/Results/{name}.csv\", separator=\",\", append=False)\n",
        "]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPOghGVvP4AA"
      },
      "source": [
        "epochs=150\n",
        "# model.load_weights(\"/content/drive/MyDrive/Thesis/Results/MbNET_t4/cp.ckpt\")\n",
        "\n",
        "history = model.fit(\n",
        "                    train_dataset,\n",
        "                    validation_data=val_dataset,\n",
        "                    epochs=epochs,\n",
        "                    callbacks= [cp_callback]\n",
        "                    )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03ig5scfOt7v"
      },
      "source": [
        "## Learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI2LT8TavfP-"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(10, 5), dpi=200)\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training')\n",
        "plt.plot(epochs_range, val_acc, label='Validation')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim(0, 1)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training')\n",
        "plt.plot(epochs_range, val_loss, label='Validation')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.ylim(0, 0.8)\n",
        "\n",
        "plt.savefig(f'/content/drive/MyDrive/Thesis/Graphs/{name}.png')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xszAIrLkOx3J"
      },
      "source": [
        "## Model predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Jwulwc0_e-L"
      },
      "source": [
        "cm_predictions = []\n",
        "cm_correct_labels = []\n",
        "\n",
        "for image_batch, labels_batch in test_dataset:\n",
        "\n",
        "  #Retrieve a batch of images from the test set\n",
        "  image_batch, label_batch = test_dataset.as_numpy_iterator().next()\n",
        "  predictions = model.predict_on_batch(image_batch).flatten()\n",
        "\n",
        "  # Apply a sigmoid since our model returns logits\n",
        "  # predictions = tf.nn.sigmoid(predictions)\n",
        "  \n",
        "  predictions = tf.where(predictions < 0.5, 0, 1)\n",
        "  predictions = predictions.numpy()\n",
        "  cm_predictions.append(predictions)\n",
        "\n",
        "  cm_correct_labels.append(label_batch)\n",
        "\n",
        "  plt.figure(figsize=(20, 10))\n",
        "  for i in range(BATCH_SIZE):\n",
        "    ax = plt.subplot(4, 8, i + 1)\n",
        "    image = image_batch[i]\n",
        "    plt.imshow(image[:, :, :3])\n",
        "    correct = (predictions[i] == label_batch[i])\n",
        "    title = (r'Pred: {} Label: [{}] '.format(predictions[i], label_batch[i]))\n",
        "    plt.title(title, fontsize=12, color='red' if correct == False else 'black')\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "cm_predictions = np.asarray(cm_predictions).flatten()\n",
        "cm_correct_labels = np.asarray(cm_correct_labels).flatten()\n",
        "\n",
        "print(\"Correct   labels: \\n\", cm_correct_labels.shape, cm_correct_labels)\n",
        "\n",
        "print('Predictions:\\n', cm_predictions.shape, cm_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ivlb3cMlLo9l"
      },
      "source": [
        "# confusion matrix\n",
        "cf_matrix = confusion_matrix(cm_correct_labels, cm_predictions)\n",
        "\n",
        "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
        "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
        "                cf_matrix.flatten()]\n",
        "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
        "                     cf_matrix.flatten()/np.sum(cf_matrix)]\n",
        "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
        "          zip(group_names,group_counts,group_percentages)]\n",
        "labels = np.asarray(labels).reshape(2,2)\n",
        "sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')\n",
        "\n",
        "plt.savefig(f'/content/drive/MyDrive/Thesis/SA/{name}-cf.png', dpi=200)\n",
        "\n",
        "# outcome values order in sklearn\n",
        "tn, fp, fn, tp = confusion_matrix(cm_correct_labels, cm_predictions).reshape(-1)\n",
        "print('Outcome values : \\n', 'TP :', tp, '\\n FN :', fn, '\\n FP :', fp, '\\n TN :', tn)\n",
        "\n",
        "# classification report for precision, recall f1-score and accuracy\n",
        "matrix = classification_report(cm_correct_labels, cm_predictions)\n",
        "print('Classification report : \\n',matrix)\n",
        "\n",
        "\n",
        "report = pd.DataFrame(classification_report(cm_correct_labels, cm_predictions, \n",
        "                                            output_dict=True)).transpose()\n",
        "report.to_csv(f'/content/drive/MyDrive/Thesis/Graphs/{name}-report.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}